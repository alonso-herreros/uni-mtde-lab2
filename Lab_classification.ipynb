{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prDPWIn7cMf3"
      },
      "source": [
        "# **Modern Theory of Detection and Estimation**\n",
        "## **Lab 2: Machine Learning for Classification**\n",
        "### **Academic Year 2024/2025**\n",
        "\n",
        "Bachelor's Degree in:\n",
        "*   Mobile and Space Communications Engineering (Groups 61 and 65)\n",
        "*   Sound and Image Engineering (Groups 66 and 69)\n",
        "*   Telecommunication Technologies Engineering (Groups 91, 92, and 95)\n",
        "*   Telematics Engineering (Groups 71 and 79)\n",
        "\n",
        "**Signal Theory and Communications Department - UC3M**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRkkuSWjciag"
      },
      "source": [
        "# **Logistics**\n",
        "\n",
        "\n",
        "**Setup Instructions**\n",
        "\n",
        "*   Download the file available on Aula Global (in the master group).\n",
        "*   Save the file to your private folder and navigate to it. Ensure it contains the file named \"**Lab_classification_student_24_25.ipynb**\".\n",
        "*   Open Google Colab and upload the notebook.\n",
        "*   Be patient as it may take a minute for a new Jupyter server to initialize.\n",
        "\n",
        "Once the server is ready, you're all set to begin! The notebook includes designated areas for writing code solutions and answering questions.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw9Lr49yLKGD"
      },
      "source": [
        "#**Objective**\n",
        "\n",
        "Maternal health is a critical global concern, particularly in low-resource settings where access to quality healthcare is limited. According to the report \"*Trends in Maternal Mortality*\" published in February 2023 by the World Health Organization (WHO), **approximately 287,000 women died from complications related to pregnancy and childbirth in 2020** — an alarming statistic equivalent to one maternal death every two minutes worldwide. Many of these deaths were preventable with timely interventions and adequate care. This report presents the most recent estimates available as of November 2024.\n",
        "\n",
        "\n",
        "\n",
        "**Accurately predicting maternal health risks is essential to preventing these tragedies**. Women with seemingly similar health profiles can experience vastly different outcomes, ranging from smooth deliveries to life-threatening complications. Identifying high-risk cases early and understanding the factors driving these differences are crucial steps in improving maternal health outcomes.\n",
        "\n",
        "\n",
        "Risk factors for maternal health complications are diverse, spanning physical health issues, socio-economic conditions, and other contextual factors. **By leveraging machine learning techniques applied to clinical data, we aim to develop some models capable of accurately predicting maternal health risks**. This approach enables healthcare providers to deliver timely and targeted interventions, ultimately saving lives and improving maternal outcomes.\n",
        "\n",
        "In this assignment, we will use the **Maternal Health Risk Data** to **develop machine learning models** that **classify the risk level (low, medium, or high) for pregnant women**. The primary goal is to enhance maternal outcomes by accurately identifying high-risk cases and ensuring timely and appropriate care for those in need.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**LET'S GET STARTED!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8c3LTWqMac4"
      },
      "source": [
        "Let's begin by setting up our environment with the required libraries. Once the setup is complete, we will proceed to import and explore the dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zej6NmEBE4fn"
      },
      "outputs": [],
      "source": [
        "#Import the Python libraries that will be used in this lab assignment\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#To avoid warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zJHE9erMlOH"
      },
      "source": [
        "# 1.&nbsp;Maternal Health Risk Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB9P9IoxNCWO"
      },
      "source": [
        "## 1.1 Description\n",
        "\n",
        "The Maternal Health Risk Data was collected from various sources, including hospitals, community clinics, and maternal healthcare facilities, through an IoT-based risk monitoring system. This system facilitates real-time monitoring of critical health parameters, such as blood pressure, heart rate, and glucose levels. By integrating IoT devices into healthcare, the system enables continuous data collection, reducing the need for frequent hospital visits —particularly beneficial in remote or underserved areas.\n",
        "\n",
        "\n",
        "The dataset comprises **$1014$ samples**, each containing **six numerical features** that provide insights into various health parameters relevant to maternal health. Each sample is labeled with a risk level, which falls into one of three classes:\n",
        "\n",
        "*   **Low Risk** (`low_risk`, class $1$): It indicates a relatively low likelihood of maternal health complications, requiring standard monitoring.\n",
        "*   **Medium Risk** (`mid_risk`, class $2$): It indicates a moderate likelihood of complications, suggesting the need for closer monitoring or preventive interventions.\n",
        "\n",
        "*   **High Risk** (`high_risk`, class $3$): It indicates a high likelihood of maternal health complications, requiring immediate attention and potentially urgent medical intervention.\n",
        "\n",
        "For additional information about the Maternal Health Risk Data, please refer to the dataset's official page: [Maternal Health Risk Data](https://www.kaggle.com/datasets/csafrit2/maternal-health-risk-data).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5owfoAXQpMn"
      },
      "source": [
        "## 1.2 Getting the dataset\n",
        "\n",
        "The first step in this assignment is to download the dataset we will be working with. To do this, we will use the `ucimlrepo` library, which facilitates seamless access to datasets from the\n",
        "[UCI Machine Learning Repository](https://archive.ics.uci.edu/). This library allows us to load data directly into our environment without the need for manual downloads. To install it, execute the following code cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8X8DcgfQI2R"
      },
      "outputs": [],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N77ehuSgvzUe"
      },
      "source": [
        "If the installation is successful, you should see a confirmation message similar to the following:\n",
        "\n",
        "`Installing collected packages: ucimlrepo` \\\\\n",
        "`Successfully installed ucimlrepo-0.0.7`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFGocvIivnqR"
      },
      "source": [
        "Once the library is installed, execute the following code cell to load the dataset. This will provide the features ($\\mathbf{X}$) and the target labels ($y$).\n",
        "\n",
        "\n",
        "The labels ($y$) represent the class or category for each sample. As previously mentioned, they can take one of three values:\n",
        "*   `low_risk`\n",
        "*   `mid risk`\n",
        "*   `high risk`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3QZ7bDeQD3v"
      },
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "maternal_health_risk = fetch_ucirepo(id=863)\n",
        "\n",
        "X = maternal_health_risk.data['features'].values\n",
        "y = maternal_health_risk.data['targets']['RiskLevel'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUdREVykxP9g"
      },
      "source": [
        "The following explanation provides an overview of the data types stored in variables `X` and `y`:\n",
        "\n",
        "*   `X`: This variable contains the input data or features of the dataset. Specifically, X is a 2D `numpy.ndarray` where each row corresponds to a sample (a maternal health record), and each column corresponds to a specific feature (e.g., blood pressure, heart rate, glucose level, etc.).\n",
        "\n",
        "*   `y`: This variable contains the class labels (target variable) that indicate the risk level (`low risk`, `mid risk`, or `high risk`) for each sample. It is a one-dimensional `numpy.ndarray`, where each element corresponds to the risk level of a specific sample in `X`.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk-MJRUOOGpm"
      },
      "source": [
        "## 1.3 Dataset description\n",
        "\n",
        "As outlined in Section 1.1, each sample in the dataset consists of six attributes, or features, representing key health indicators used to assess maternal health risks. These attributes are described as follows:\n",
        "\n",
        "1.   **Age** (`float64`): The age of the woman (in years) at the time of pregnancy.\n",
        "2.   **SystolicBP** (`float64`): Systolic blood pressure (in mmHg). It represents the upper value of blood pressure, which is a critical health indicator during pregnancy.\n",
        "3.   **DiastolicBP** (`float64`): Diastolic blood pressure (in mmHg). This is the lower value of blood pressure. This parameter, along with SystolicBP, is a crucial indicator for monitoring maternal health during pregnancy.\n",
        "4.   **BS** (`float64`):  Blood glucose level (in mmol/L). It is an essential indicator for assessing maternal health and identifying risks such as gestational diabetes.\n",
        "5.   **BodyTemp** (`float64`): Body temperature of the pregnant woman (in degrees Celsius).\n",
        "\n",
        "6.   **HeartRate** (`float64`):  Resting heart rate (in beats per minute). It reflects an important physiological parameter used to monitor cardiovascular health and overall well-being during pregnancy.\n",
        "\n",
        "Additionally, we have the target variable:\n",
        "\n",
        "*   **RiskLevel** (`object`): The classification target representing the predicted risk intensity level during pregnancy (`low risk`, `mid risk`, or `high risk`). This level is derived from the values of the aforementioned attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmnupiIg24gj"
      },
      "source": [
        "Let's display the data for the first sample to gain an overview. To explore other samples, simply modify the index inside the square brackets of `iloc`.\n",
        "\n",
        "*What is the age and maternal health risk level of the woman in the last position?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qAE8xni2QDb"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data=maternal_health_risk.data['features'], columns=maternal_health_risk.feature_names)\n",
        "\n",
        "# Add the 'RiskLevel' column (target)\n",
        "df['RiskLevel'] = maternal_health_risk.data['targets']['RiskLevel']\n",
        "\n",
        "# Access a specific row, for example, row 0\n",
        "row = df.iloc[0]\n",
        "print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYqansV-7lZN"
      },
      "source": [
        "Finally, because algorithms require numerical data, we need to convert the `RiskLevel` values from words to numbers. Using a mapping dictionary, each risk level will be assigned a numerical code:\n",
        "\n",
        "*   `low risk` $\\rightarrow 1$\n",
        "*   `mid risk`$\\rightarrow 2$\n",
        "*   `high risk`$\\rightarrow 3$\n",
        "\n",
        "To perform this conversion, execute the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iPETIxAXbP_"
      },
      "outputs": [],
      "source": [
        "# Define the mapping dictionary\n",
        "risklevel = {\"low risk\": 1, \"mid risk\": 2, \"high risk\": 3}\n",
        "\n",
        "# Map the values of y\n",
        "y = np.array([risklevel[val] for val in y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUvIzLv785fX"
      },
      "source": [
        "You can now observe how each label in `y` has been converted into a numerical value representing the corresponding risk level. To verify this, use the following code to view the last value in `y`:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lEMt6Cd9EG0"
      },
      "outputs": [],
      "source": [
        "# Display the risk level for the last sample\n",
        "print(\"The numerical risk level for the last sample is:\", y[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09tss3TLU2bS"
      },
      "source": [
        "## 1.4 Dataset analysis\n",
        "\n",
        "Before proceeding with the analysis, it is essential to understand the basic structure of our dataset. Knowing the number of samples and features will provide an overview of its size and complexity. Additionally, we will examine the distribution of samples across the categories in the target variable.\n",
        "\n",
        "**How many samples are there in this dataset?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMyVAEh2U0U7"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "n_samples =\n",
        "print(\"The number of samples is: \", n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZr3BAVIVCKc"
      },
      "source": [
        "**How many features does each sample have?** Print the result!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj1QdUj8VGpH"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "n_features =\n",
        "print(\"The number of features is: \", n_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB_U-l-UVL99"
      },
      "source": [
        "Now, let's analyze the class distribution. **How many samples are there in each risk level category?**\n",
        "\n",
        "Print the results to better understand the dataset's balance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJp01exFVPT_"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# HINT: You can use the `.count_nonzero()` method from the Numpy library to count occurrences of each risk level\n",
        "class_1 =\n",
        "class_2 =\n",
        "class_3 =\n",
        "\n",
        "print('The number of low risk level for pregnant women is: ', class_1)\n",
        "print('The number of medium risk level for pregnant women is: ', class_2)\n",
        "print('The number of high risk level for pregnant women is: ', class_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE151u23VMMS"
      },
      "source": [
        "Finally, create a bar chart to visualize the distribution of risk level classes in the dataset. This will provide a clear representation of the class balance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3AyrLlRkbI2"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "def addlabels(x,y):\n",
        "    for i in range(len(x)):\n",
        "        plt.text(i,y[i],y[i])\n",
        "\n",
        "#...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-DYMyC_ETkB"
      },
      "source": [
        "---\n",
        "\n",
        "**Question**: Which category or class contains the highest number of samples, and which one has the lowest?\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqjJtmv8EuMO"
      },
      "source": [
        "# <font color = 'black'> 2. Data preparation: Splitting and standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4N2NIFnmAFG"
      },
      "source": [
        "## 2.1 Separation in training and test set\n",
        "\n",
        "As explained in Lab 1 (*Machine Learning for Regression*), splitting the dataset is essential to ensure an unbiased evaluation of prediction performance. In most cases, it is sufficient to randomly divide the dataset into two subsets:\n",
        "*   **Training set**: This subset is used to train, or **fit**, **the model**. For instance, it is employed to determine the optimal weights (coefficients) for algorithms such as linear regression or logistic regression.\n",
        "*   **Test set**: This subset is reserved for an **unbiased evaluation of the model's final performance**. It should not be used for training or validation tasks.\n",
        "\n",
        "The [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)function from the `scikit-learn` library can easily perform this split for you!\n",
        "\n",
        "\n",
        "\n",
        "**Note:** When comparing machine learning algorithms, it is desirable to fit and evaluate them on the same subsets of the dataset.  This can be ensured by setting a fixed seed for the pseudo-random number generator used during dataset splitting. In the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function, this is achieved by specifying the `random_state` parameter with a fixed integer value.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V0edSt7wxKD"
      },
      "source": [
        "![train_test.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRzPfddOmKsA"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "\n",
        "*   Split your **data into training and testing sets**, using a **70/30 split ratio**.\n",
        "\n",
        "For consistency, use the following variable names for the resulting NumPy arrays:\n",
        "`X_train`, `X_test`, `y_train`, and `y_test`.\n",
        "\n",
        "$\\underline{\\text{Note}}$: To ensure you are working with the same dataset split as your colleagues, please set `random_state = 42` as the seed in the `train_test_split` function.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiRT7ZWJFdaR"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZDLe3uIOxCd"
      },
      "source": [
        "**How many samples are there in the training and test subsets, respectively?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjaMM6EdO3GG"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n",
        "n_tr  =\n",
        "n_tst =\n",
        "print('The number of training samples is:', n_tr)\n",
        "print('The number of test samples is:', n_tst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-raNiaEvNly"
      },
      "source": [
        "Let's verify that everything is correct.\n",
        "\n",
        "**Does the sum of the number of samples in the training and test sets equal the total number of samples?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOCvEDdEmiLF"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n",
        "n_tot =\n",
        "print('The total number of samples is: ', n_tot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvEL8h8ORKUt"
      },
      "source": [
        "## 2.2 Standardization of features\n",
        "In Lab 1 (*Machine Learning for Regression*), we discussed the importance of feature standardization in machine learning algorithms. Standardization involves rescaling features so they have a mean of zero and a standard deviation of one. This process ensures that each feature contributes equally to the model's performance, particularly for algorithms sensitive to data scale.\n",
        "\n",
        "In this lab, we will apply standardization separately to the training and test sets. The [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) class from `scikit-learn` can efficiently perform this task for you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYLix5_ELJZG"
      },
      "source": [
        "**Your task is as follows**:\n",
        "*   Use the `StandardScaler` class from the `sklearn.preprocessing module` to standardize the features in `X_train` and `X_test`.\n",
        "\n",
        "$\\underline{\\text{Note}}$: When standardizing, it is crucial to fit the scaler **only** on the training data and then apply the same transformation to the test data. This approach prevents information from the test set from leaking into the training process, ensuring an unbiased evaluation of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf9LfGNhLxLv"
      },
      "source": [
        "**Here's how you can do it**:\n",
        "\n",
        "\n",
        "*  Create an instance of `StandardScaler`.\n",
        "*  Fit the scaler using the training data (`X_train`).\n",
        "*  Generate two new matrices as follows:\n",
        "    - `X_train_s`: This matrix contains the standardized version of `X_train`, obtained by transforming it with the fitted scaler.\n",
        "    - `X_test_s`: This matrix contains the standardized version of `X_test`, obtained by applying the same transformation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-P23sEOz038"
      },
      "source": [
        "![standarization2.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJxDzdX6Gsnd"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n",
        "#...\n",
        "#X_train_s = ...\n",
        "#X_test_s = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV9VtjEOSTXL"
      },
      "outputs": [],
      "source": [
        "#Let's check out that everything is ok!\n",
        "print('TRAINING SET')\n",
        "print('Mean of each feature: ', np.round(np.mean(X_train_s,0),2))\n",
        "print('Std of each feature: ', np.round(np.std(X_train_s,0),2))\n",
        "\n",
        "print('\\nTEST SET')\n",
        "print('Mean of each feature: ', np.round(np.mean(X_test_s,0),2))\n",
        "print('Std of each feature: ', np.round(np.std(X_test_s,0),2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNARkhFeFt5M"
      },
      "source": [
        "# <font color = 'black'> 3. Cross-Validation for hyperparameter selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYiBLB1kFwnP"
      },
      "source": [
        "## 3.1 Introduction\n",
        "\n",
        "The performance of most machine learning algorithms strongly depends on the selected hyperparameter values. Hyperparameters control various aspects of the learning process, such as the model's complexity, the learning rate, or the trade-off between bias and variance. **Selecting appropriate hyperparameter values can result in more accurate and generalizable models, whereas poor choices may lead to underfitting, overfitting, or inefficient training**. Therefore, careful hyperparameter tuning is essential to optimize the model's performance and ensure effective generalization to new, unseen data.\n",
        "\n",
        "As you may recall from Lab 1(*Machine Learning for Regression*), the original dataset was divided into three subsets: **train**, **test**, and **validation**. In this assignment, however, the dataset is divided into only two subsets: **train** and **test**. This difference arises because, in the previous assignment, we introduced an approximation of the widely used method for hyperparameter selection: **cross-validation**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBHqitJjGjMj"
      },
      "source": [
        "## 3.2 Cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4p15ZOAG_Td"
      },
      "source": [
        "\n",
        "### 3.2.1 Definition\n",
        "\n",
        "Cross-validation is a commonly used procedure in machine learning to simulate the effect of training a model on a subset of data and evaluating its generalization capabilities on a *separate dataset*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seQggw7LsI9-"
      },
      "source": [
        "### 3.2.2 Procedure\n",
        " The cross-validation process involves the following steps:\n",
        "*  Randomly partition the training dataset into\n",
        "$N$ disjoint subsets of similar sizes. Each of these subsets is called a **fold** in machine learning terminology, leading to the term **$N$-fold cross-validation**.\n",
        "\n",
        "*   Suppose we choose $N=3$ folds. This means the training data $(X_{\\text{train}}, Y_{\\text{train}})$ has been split into three subsets: $(X_1, Y_1)$, $(X_2, Y_2)$, and $(X_3, Y_3)$, such that $(X_1, Y_1) \\cup (X_2, Y_2) \\cup (X_3, Y_3) = (X_{\\text{train}}, Y_{\\text{train}})$\n",
        "\n",
        "  and the subsets are mutually exclusive.\n",
        "  - Create an instance of the model with the chosen hyperparameters. Cross-validation then proceeds with the following steps in a loop:\n",
        "\n",
        "      For $n=1,2,\\dots,N$ iterations:  \n",
        "      1. Choose $(X_n,Y_n)$ as the **validation set** for iteration $n$.\n",
        "      2. Combine the remaining subsets (excluding the validation set) to form the **training set** for iteration $n$.\n",
        "      3. Fit the model instance with the training set of step $2$.\n",
        "      4. Evaluate  the model instance (using the `score()` method or another evaluation metric) with the validation set of step $1$.\n",
        "      5. Record the *score* achieved in iteration $n$.\n",
        "\n",
        "  - Once the loop is completed, collect the $N$ scores, each corresponding to the evaluation of the model fitted on a specific iteration using its respective validation set.\n",
        "\n",
        "  - Estimate the **true score** of the model instance trained on the entire dataset by calculating the mean and standard deviation of the $N$ validation scores.\n",
        "\n",
        "Typical values for the number of folds include $N \\in \\{3, 5, 10\\}$.  **For this assignment**, please use the default setting of **$5$-fold cross-validation**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpeB7DGf9hg7"
      },
      "source": [
        "## 3.3 Cross validation with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBiz27JAUuua"
      },
      "source": [
        "### 3.3.1 Definition of `GridSearchCV`\n",
        "\n",
        "Perhaps the student is wondering: Do I need to implement everything mentioned in the previous section? The answer is no. The cross-validation process in this assignment is handled automatically using [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). This class performs an exhaustive search over specified parameter values for a given estimator (or classifier in this case). To fully understand how it works, it is helpful to first explain a few key concepts.\n",
        "\n",
        "\n",
        "*   **Grids of hyperparameters**:\n",
        "\n",
        "      This method involves creating a **grid** where each dimension corresponds to one of the hyperparameters to be optimized. The range of values for each hyperparameter defines the points along its corresponding dimension. This approach explores **discrete ranges** for each hyperparameter.\n",
        "\n",
        "      For models that depend on a large number of hyperparameters, it is important to carefully consider the granularity of each range. A high granularity can lead to a combinatorial explosion in the grid size, making it difficult to manage and computationally expensive.\n",
        "\n",
        "\n",
        "*   **Cross-validation to explore the grid**:\n",
        "\n",
        "  The grid is explored through a loop that iterates over all its nodes, performing cross-validation at each one.  The detailed process is as follows:\n",
        "\n",
        "  For each node in the grid:  \n",
        "  1. Create an instance of the model with the hyperparameters set to the values corresponding to that specific node.\n",
        "  2. Perform **cross-validation** to estimate the model's test performance using the hyperparameter values for that node.\n",
        "  3. Record the cross-validation score for the node.\n",
        "\n",
        "Once all nodes have been evaluated, the results provide a performance estimate for each hyperparameter combination, which can be used to select the optimal configuration.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWWcIiy69vpF"
      },
      "source": [
        "### 3.3.2 Parameters of `GridSearchCV`\n",
        "\n",
        "Before using `GridSearchCV`, it's important to understand its key parameters:\n",
        "*   `estimator`: The model or estimator to which `GridSearchCV` will be applied. For example, a classifier such as `sklearn.neighbors.KNeigborsClassifier`.\n",
        "*   `param_grid`: The parameter space to search, specified as a dictionary where the keys are parameter names (`str`), and the values are lists of potential values to try for each parameter. Alternatively, it can be a list of such dictionaries, allowing `GridSearchCV` to explore multiple grids defined by each dictionary. This setup enables flexible searches over any combination of parameters.\n",
        "\n",
        "\n",
        "*  `scoring`: The evaluation metric used to assess the performance of the cross-validated model. By default, the estimator's built-in scoring function is used —for example, `sklearn.metrics.accuracy_score` for classification tasks or `sklearn.metrics.r2_score` for regression tasks. Custom scoring metrics can also be provided by specifying a callable or a predefined scoring string.\n",
        "\n",
        "*  `cv`: The number of splits used for cross-validation. By default, this parameter is set to $5$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwemnJJnSf1O"
      },
      "source": [
        "# <font color = 'black'> 4. Multiclass classification </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCzbZnQ5TrDf"
      },
      "source": [
        "## 4.1 Introduction\n",
        "\n",
        "Once our data is prepred, we will perform a classification task involving three classes: **low risk**, **medium risk**, and **high risk**. This is a **multiclass classification** problem. To address it, we will evaluate the performance of the following classifiers::\n",
        "\n",
        "**Parametric classifiers**:\n",
        "*   Linear Discriminant Analysis (LDA)\n",
        "\n",
        "**Non-parametric classifiers**:\n",
        "*   $k$-Nearest Neighbors ($k$-NN)\n",
        "*   Decision Tree (DT)\n",
        "*   Random Forest (RF)\n",
        "\n",
        "\n",
        "\n",
        "In the following section, we will introduce the **metrics** used to evaluate the classifiers: **accuracy** and the **confusion matrix**. **Accuracy** is chosen because it provides a straightforward measure of the proportion of correctly classified samples out of the total. This metric is particularly suitable for balanced datasets, where each class contains a similar number of samples, as it offers a clear indication of the classifier's overall performance.\n",
        "\n",
        "The **confusion matrix**, on the other hand, extends its utility to multiclass problems by providing a detailed breakdown of the classifier's predictions for each class. It shows the counts of correct predictions (on the diagonal) and misclassifications (off-diagonal), offering insights into which classes are being confused by the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0uxQ_fNX_Rv"
      },
      "source": [
        "## 4.2 Classification evaluation metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nDUNtj6xRSg"
      },
      "source": [
        "### 4.2.1 Accuracy rate\n",
        "**Accuracy rate**  measures the performance of a classification model by calculating the ratio of correct predictions to the total number of predictions. This metric is applicable to both multiclass and binary classification problems.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}} \\,\\,(\\times 100)\n",
        "$$\n",
        "\n",
        "Accuracy is straightforward to compute and easy to interpret, making it one of the most widely used metrics for evaluating classifier models. However, its effectiveness diminishes when the class distribution is highly imbalanced, as it may fail to reflect the model'ss true performance (a topic beyond the scope of this assignment).\n",
        "\n",
        "> **Implementation in Python:**\n",
        "\n",
        "> To compute the accuracy of a classifier on the test set, you can use the [accuracy_score](https://scikit-learn.org/dev/modules/generated/sklearn.metrics.accuracy_score.html)  function from the `scikit-learn` library. This function calculates the ratio of correctly classified samples to the total number of samples. Additionally, many classifiers in `scikit-learn` provide a `score()` method that directly computes accuracy by default, simplifying the evaluation process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD5AvdPgxXgZ"
      },
      "source": [
        "### 4.2.2 Confusion matrix\n",
        "\n",
        "The **confusion matrix** is a powerful tool for evaluating the performance of a classification model. Each class is represented by a corresponding row and column, offering a detailed breakdown of how accurately the model classifies instances of each class. It highlights both correct classifications (on the diagonal) and misclassifications (off-diagonal), providing valuable insights into the model's strengths and weaknesses.\n",
        "\n",
        "In a confusion matrix for $C$ classes, it forms a square matrix of size $C\\times C$, where:\n",
        "*   **Rows represent the actual/true classes** of instances in the test set. represent the true classes of the instances in the dataset.\n",
        "*   **Columns represent the predicted classes** assigned by the classifier.\n",
        "\n",
        "Each element $c(i,j)$ indicates the number of instances of class $i$ (true class) that were predicted as class $j$.Therefore:\n",
        "\n",
        "*   **Main diagonal**: The cells in the main diagonal (where $i=j$) represent the counts of correctly classified instances for each class.  For example, $c(A,A)$ indicates the number of samples correctly classified as class A.\n",
        "*   **Off-diagonal cells**: These cells represent misclassified samples. For instance, $c(i,j)$  where $i\\neq j$ indicates the number of samples belonging to class $i$ that were incorrectly predicted as class $j$.\n",
        "\n",
        "\n",
        "**Example interpretation of this matrix**:\n",
        "\n",
        "\\begin{array}{c|ccc}\n",
        "           & \\text{Predicted A} & \\text{Predicted B} & \\text{Predicted C} \\\\\n",
        "    \\hline\n",
        "    \\text{Actual A} & 30 & 5 & 2 \\\\\n",
        "    \\text{Actual B} & 4 & 40 & 6 \\\\\n",
        "    \\text{Actual C} & 1 & 3 & 50 \\\\\n",
        "\\end{array}\n",
        "\n",
        "In this example:\n",
        "*   Cell $(A,A)=30$: This indicates that $30$ samples of class A were correctly classified as class A (true positives for class A).\n",
        "*   Cell $(A,B)=5$:  This means $5$ samples of class A were misclassified as class B.\n",
        "*   Cell $(B,C)=6$: This indicates $6$ samples of class B were incorrectly predicted as class C.\n",
        "\n",
        "The **accuracy** is calculated by **dividing the sum of the main diagonal values** (correctly classified instances) **by the total number of samples**.\n",
        "\n",
        "For instance, using the confusion matrix provided earlier, the accuracy would be:\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{30+40+50}}{30+5+2+4+40+6+1+3+50} = \\frac{120}{141} \\approx 0.8511 (85.11\\%)\n",
        "$$\n",
        "\n",
        "In summary, this matrix helps identify which classes are more challenging for the model to classify correctly. It highlights areas where the model struggles, which can guide improvements such as rebalancing class distributions, collecting more data for underperforming classes, or fine-tuning hyperparameters.\n",
        "\n",
        "\n",
        "\n",
        "> **Implementation in Python:**\n",
        "\n",
        "> To compute the confusion matrix and evaluate the accuracy of the classifier on the test set, you can use [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) from `scikit-learn`. For visualization, the [`ConfusionMatrixDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html) class provides a straightforward way to plot the matrix and gain insights into the model's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P86CgtSxUkJg"
      },
      "source": [
        "## 4.3 Implementation and evaluation of classifiers' performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Po3BNYKhVIR"
      },
      "source": [
        "### 4.3.1 Linear Discriminant Analysis (LDA)\n",
        "\n",
        "**Linear Discriminant Analysis** (LDA) is a classifier that projects data onto a lower-dimensional space to maximize class separability. It achieves this by finding linear combinations of the features that best distinguish between classes, creating decision boundaries in the form of hyperplanes. This approach is particularly useful for dimensionality reduction in multiclass problems, as it retains the most discriminative information.\n",
        "\n",
        "In `scikit-learn`, the [LinearDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) class provides an easy-to-use implementation of LDA. **For this classifier, there is no need to optimize any hyperparameters, as the default values provide a reliable starting point. We will use these defaults to fit and evaluate the LDA classifier**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXWlk9stnRXq"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "*   Fit an LDA model using the **standardized training dataset** and **default hyperparameters**.\n",
        "\n",
        "  Please note that if you use the **standardized training dataset to fit the model**, any **metric** you wish to compute on the **test set** must also be based on **standardized features**.\n",
        "*   Calculate the accuracy rate (as a percentage) on both the training and test sets. Use the `score()` method to evaluate the model and round the results to two decimal places.\n",
        "*   Print the accuracy values for both datasets in a clear format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWhHJ2WJHBkf"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtUICvtFO9t1"
      },
      "source": [
        "---\n",
        "**Question:** What is the value of the hyperparameter `n_components` used? What does this mean?\n",
        "\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2dKs2HdlpbN"
      },
      "source": [
        "To answer this question, we can visually explore how LDA projects the data onto a two-dimensional subspace. This helps us better understand the separation between classes. The following code demonstrates how to project each standardized training sample onto this 2D plane by setting `n_components=2` in the LDA model. Each sample is then plotted according to its category or class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRDAbTf-k8-P"
      },
      "outputs": [],
      "source": [
        "X_lda = clf_LDA.fit_transform(X_train_s, y_train)\n",
        "\n",
        "# Separate the samples of each class.\n",
        "X_lda_clase_1 = X_lda[y_train == 1]\n",
        "X_lda_clase_2 = X_lda[y_train == 2]\n",
        "X_lda_clase_3 = X_lda[y_train == 3]\n",
        "\n",
        "# Plot the classes in the 2D LDA space.\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_lda_clase_1[:, 0], X_lda_clase_1[:, 1], color='c', marker='*', label='Class 1 (Low Risk)')\n",
        "plt.scatter(X_lda_clase_2[:, 0], X_lda_clase_2[:, 1], color='y', marker='o', label='Class 2 (Medium Risk)')\n",
        "plt.scatter(X_lda_clase_3[:, 0], X_lda_clase_3[:, 1], color='g', marker='s', label='Class 3 (High Risk)')\n",
        "\n",
        "# Labels and legend.\n",
        "plt.xlabel('LDA1')\n",
        "plt.ylabel('LDA2')\n",
        "plt.title('LDA Projection with 2 Components')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LPaRl9yShSS"
      },
      "source": [
        "---\n",
        "\n",
        "**Question:** Based on the projection in the figure, which classes appear to be more easily confused with each other? Justify your answer by analyzing the overlap in the plot.\n",
        "\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQuDOe844ywI"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "*  Calculate the **confusion matrix** for **the test set**. This matrix will help analyze how effectively the classifier distinguishes between classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTx6pFMA43ia"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciwmOX2c5GnM"
      },
      "source": [
        "---\n",
        "**Questions:** Which class is the easiest to predict correctly? Which class is most confused with others? Which classes are commonly confused with each other?\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_mMq8G1rEO0"
      },
      "source": [
        "What happens now if `n_components=1`? Run the next code cell to see the result!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lcCZTIpHEpe"
      },
      "outputs": [],
      "source": [
        "clf_LDA_1D = LinearDiscriminantAnalysis(n_components=1)\n",
        "X_lda = clf_LDA_1D.fit_transform(X_train_s,y_train)\n",
        "plt.xlabel('LDA1')\n",
        "X_lda_clase_1 = X_lda[y_train==1]\n",
        "X_lda_clase_2 = X_lda[y_train==2]\n",
        "X_lda_clase_3 = X_lda[y_train==3]\n",
        "\n",
        "y1 = np.ones((X_lda_clase_1.shape[0],1))\n",
        "y2 = np.ones((X_lda_clase_2.shape[0],1))\n",
        "y3 = np.ones((X_lda_clase_3.shape[0],1))\n",
        "\n",
        "plt.plot(X_lda_clase_1, y1, '*c', label='Class 1 (Low Risk)')\n",
        "plt.plot(X_lda_clase_2, y2, 'oy', label='Class 2 (Medium Risk)')\n",
        "plt.plot(X_lda_clase_3, y3, 'sg', label='Class 3 (High Risk)')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phJA7xkKm7wv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Question:** Do you expect to obtain the same accuracy rates on the training and test sets when using `n_components=2` as when using `n_components=1`? Justify your answer.\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49Dz3B_Cdab_"
      },
      "source": [
        "### 4.3.2  $k$-NN classifier\n",
        "\n",
        "**$k$-Nearest Neighbors** (commonly referred to as **$k$-NN**) is a versatile, non-parametric classification algorithm suitable for both multiclass and binary classification problems. It classifies a sample based on the majority class among its $k$ nearest neighbors in the feature space. The decision boundaries formed by $k$-NN are typically non-linear, making it particularly effective for datasets where classes are not linearly separable. The algorithm's performance is influenced by the choice of $k$, the distance metric, and the weighting of neighbors.\n",
        "\n",
        "To implement $k$-NN in Python, we will use the [KNeighborsClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) class from `scikit-learn`. This class provides several hyperparameters that can be tuned to optimize the algorithm'ss performance:\n",
        "\n",
        "*   `n_neighbors`: It specifies the number of neighbors to consider for classification. Choosing an optimal value for $k$ is crucial, as smaller values of $k$ may lead to overfitting, while larger values can result in underfitting.\n",
        "*   `weights`: It determines how neighbors are weighted. The options include:\n",
        "  *   `uniform`: All $k$ neighbors contribute equally to the classification.\n",
        "  *   `distance`: Neighbors are weighted based on their distance to the sample, so closer neighbors have a stronger influence on the classification.\n",
        "*   `metric`: Defines the distance metric used to calculate the \"nearness\" of neighbors. The default is Euclidean distance, but other options (such as Manhattan or Minkowski distances) are also available, depending on the nature of the data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syaK5z3Xdyy2"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "1.   **Hyperparameter tuning**\n",
        "\n",
        "  Use the `GridSearchCV` class to find the optimal values for `n_neighbors` (the value of $k$) and `weights`. Perform the grid search with **standardized features** to optimize the classifier's performance. The parameter values to explore are:\n",
        "    * `n_neighbors` $\\in \\{1,11,31,51,71,91,101\\}$\n",
        "    * `weights` $\\in [{\\text{uniform}, \\text{distance}}]$\n",
        "2.   **Evaluate the best model**\n",
        "  Once the optimal hyperparameters are identified, calculate the accuracy rate (as a percentage) on the test set using the `best_estimator_` attribute of `GridSearchCV`. Print the result, rounding it to two decimal places.\n",
        "\n",
        "\n",
        "Please note that if the model was **trained** using the **standardized dataset**, it must also be **evaluated** on the **standardized test set** to ensure consistency in the feature scaling.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe3Mvm07Hkvf"
      },
      "outputs": [],
      "source": [
        "#Fine-tuning hyperparameters\n",
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC_M9S5zHnPd"
      },
      "outputs": [],
      "source": [
        "#Check the best model with the test set\n",
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTjckSUQd7dH"
      },
      "source": [
        "---\n",
        "**Question:** What are the most appropriate values of the hyperparameters `n_neighbors` and `weights` that you have obtained?\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFNEWtRz2Kf9"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "*  Calculate the **confusion matrix** for the **test set** using the **best model** obtained from the **grid search**. This matrix will help you analyze how effectively the classifier distinguishes between the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8A7izgl2oFd"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHm5nSYt3ORG"
      },
      "source": [
        "---\n",
        "**Questions:** Which class is the easiest to predict correctly? Which class is most confused with others? Which classes are commonly confused with each other?\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veafkJaVt4ki"
      },
      "source": [
        "### 4.3.3 Decision tree classifier\n",
        "\n",
        "A **Decision Tree** (DT) is a powerful, non-parametric classification algorithm that can be used for both multiclass and binary classification problems. It classifies a sample by recursively splitting the feature space into regions, with each split designed to maximize class separation. The resulting model forms a tree-like structure, allowing it to adapt to complex, non-linear patterns in the data. However, this flexibility makes decision trees prone to overfitting, particularly when the tree is allowed to grow too deep.\n",
        "\n",
        "\n",
        "To implement a Decision Tree in Python, we will use the [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) class from `scikit-learn`. This class provides several hyperparameters that can be tuned to optimize the model's performance. Although many hyperparameters can be validated, we will focus on `max_depth`:\n",
        "\n",
        "*   `max_depth`: This hyperparameter specifies the maximum depth of the tree. Controlling the depth helps mitigate overfitting by limiting the number of splits and, consequently, the model's complexity. Smaller values for `max_depth` may lead to underfitting, as the model might not capture sufficient patterns in the data, while larger values can increase the risk of overfitting by making the tree too complex.\n",
        "\n",
        "The `DecisionTreeClassifier` class also includes other hyperparameters, such as `min_samples_split` and `min_samples_leaf`, which further control the growth of the tree. However, for simplicity, we will focus solely on validating `max_depth` in this task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0UeXsObTRu"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "1.   **Hyperparameter tuning**\n",
        "\n",
        "  Use the `GridSearchCV` class to find the optimal value for `max_depth`. Perform the grid search using **non-standardized features** to optimize the classifier's performance. The parameter values to explore are:\n",
        " * `max_depth` $\\in \\{1, 9, 17, 25,  33, 41\\}$\n",
        "\n",
        "2.   **Evaluate the best model**\n",
        "\n",
        "  Once the optimal hyperparameter is identified, calculate the accuracy rate (as a percentage) on the test set using the `best_estimator_` attribute of `GridSearchCV`. Print the result, rounding the value to two decimal places.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQCDjdx1IAE4"
      },
      "outputs": [],
      "source": [
        "#Fine-tuning hyperparameters\n",
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0ox2YUlIC8x"
      },
      "outputs": [],
      "source": [
        "#Check the best model with the test set\n",
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEuVmFkPDcmh"
      },
      "source": [
        "---\n",
        "**Question:** Which is the most appropiate value of `max_depth` that you have obtained?\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMvDxPLr3hQa"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "*  Calculate the **confusion matrix** for the **test set** using the **best model** obtained from the **grid search**.  This matrix will help you analyze how well the classifier distinguishes between classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBPB37bS3miZ"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZg6amaN3wQx"
      },
      "source": [
        "---\n",
        "**Questions:** Which class is the easiest to predict correctly? Which class is most confused with others? Which classes are commonly confused with each other?\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6TxFE-WiqAm"
      },
      "source": [
        "### 4.3.4 Random Forest classifier\n",
        "\n",
        "A **Random Forest** (RF) is an ensemble learning method that combines multiple decision trees to improve classification performance and reduce the risk of overfitting associated with a single decision tree. Each tree in the ensemble is trained on a random subset of the data, and the final classification is determined by aggregating the predictions of all trees (e.g., by majority vote). This approach creates a model that is both powerful and less prone to overfitting than a single decision tree, making it well-suited for complex classification tasks.\n",
        "\n",
        "To implement a Random Forest in Python, we will use the [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) class from `scikit-learn`. This class includes several hyperparameters that can be adjusted to optimize performance, such as the total number of terminal nodes in each tree (`max_leaf_nodes`), the minimum number of samples required to split a node (`min_samples_split`), or the minimum number of samples per leaf node (`min_samples_leaf`), similar to those in `DecisionTreeClassifier`, among others.\n",
        "\n",
        "In this assignment, we will focus on two key hyperparameters of the ensemble: the number of trees and the maximum depth of each tree. These are specified in `RandomForestClassifier` class as follows:\n",
        "\n",
        "*   `n_estimators`: This parameter defines the number of decision trees in the ensemble. Increasing the number of trees generally improves model performance but it also increases computational cost. A higher `n_estimators` value often results in a more accurate model, though the improvement diminishes beyond a certain point.\n",
        "*  `max_depth`: This parameter specifies the maximum depth of each individual tree in the forest. Limiting the depth helps prevent overfitting by restricting the number of splits in each tree, thus controlling the model's complexity. Smaller values of `max_depth` may result in underfitting, while larger values can increase the risk of overfitting.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEFMPahXOkdq"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "\n",
        "\n",
        "1.   **Hyperparameter tuning**\n",
        "\n",
        "  Use the `GridSearchCV` class to find the optimal values for both `n_estimators` and `max_depth`. Perform the grid search using **non-standardized features** to optimize the classifier's performance. The parameter values to explore are:\n",
        "\n",
        "   * `n_estimators` $ \\in \\{10, 50, 100, 150\\}$\n",
        "   * `max_depth` $\\in \\{10,20,30,35\\}$\n",
        "\n",
        "   **Note**: Hyperparameter optimization for Random Forests typically requires more time compared to other models due to the need to train multiple trees for each parameter combination.\n",
        "\n",
        "2.   **Evaluate the best model**\n",
        "\n",
        "  Once the optimal hyperparameters are identified, calculate the accuracy rate (as a percentage) on the test set using the `best_estimator_` attribute of `GridSearchCV`. Print the result, rounding the value to two decimal places.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VM-7t18KIHOq"
      },
      "outputs": [],
      "source": [
        "#Fine-tuning hyperparameters\n",
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x61OAnKMIQVE"
      },
      "outputs": [],
      "source": [
        "#Check the best model with the test set\n",
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcoNpNwvrKpx"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Question:** What are the most appropriate values of the hyperparameters `n_estimators` and `max_depth` that you have obtained?\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNPKYdpi33Jj"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "*  Calculate the **confusion matrix** for the **test set** using the **best model** obtained from the **grid search**.  This matrix will help you analyze how well the classifier distinguishes between classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lgPk_rU8362y"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ1U1wpy4AyR"
      },
      "source": [
        "---\n",
        "**Questions:** Which class is the easiest to predict correctly? Which class is most confused with others? Which classes are commonly confused with each other?\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfEkvdJff9yz"
      },
      "source": [
        "## 4.4 Best classification model\n",
        "It is often said that a picture is worth a thousand words, and visualizing our results can provide a quicker and deeper understanding of the classifiers we have developed. In this section, we will evaluate and determine which classification model is the best fit for our dataset!\n",
        "\n",
        "**Your task here is as follows:**\n",
        "\n",
        "  *  Create a bar plot representing the accuracy rate (in percentages) achieved by each classification model evaluated in this assignment. Use the **optimal hyperparameter values** for each model and display the results based on the **test set performance**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1xEu44IgoMWS"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O27KNCQdbCK"
      },
      "source": [
        "---\n",
        "**Question:** Which classification model achieved the highest accuracy rate on the test set?\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acsqL6CDpOZA"
      },
      "source": [
        "# <font color = 'black'> 5. Binary classification: Low risk vs. high risk </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7PdPbQ_fhE1"
      },
      "source": [
        "## 5.1 Transforming the multiclass problem into a binary classification task\n",
        "\n",
        "In this section, we will convert the original multiclass classification problem into a binary classification task. To accomplish this, we will focus exclusively on samples belonging to **class 1** (`low risk`) and **class 3** (`high risk`), excluding samples from other classes. By narrowing the scope to these two groups, we aim to evaluate the effectiveness of our models in distinguishing between the two most contrasting risk levels. This binary classification approach provides an opportunity to analyze the models' performance in a simpler, two-class scenario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlJHsDVOgcXX"
      },
      "source": [
        "In the following lines of code, we will create a binary classification dataset by filtering the samples belonging to class 1 (`low risk`) and class 3 (`high risk`). First, we will apply a boolean mask to select these classes from both the training and test sets. Then, we will verify the number of samples remaining after the filtering process to ensure that the desired classes have been correctly isolated for this binary classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X1sLRy8vuDy1"
      },
      "outputs": [],
      "source": [
        "# Create the boolean filter for values 1 and 3 in y\n",
        "mask_train = (y_train == 1) | (y_train == 3)\n",
        "mask_test = (y_test == 1) | (y_test == 3)\n",
        "\n",
        "# Apply the filter to X and y\n",
        "X_train_binary_s = X_train_s[mask_train]\n",
        "y_train_binary = y_train[mask_train]\n",
        "\n",
        "X_test_binary_s = X_test_s[mask_test]\n",
        "y_test_binary = y_test[mask_test]\n",
        "\n",
        "#  Convert 1 to 0 and 3 to 1 in y_train_binary and y_test_binary\n",
        "y_train_binary = np.where(y_train_binary == 1, 0, 1)\n",
        "y_test_binary = np.where(y_test_binary == 1, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFnRSosHsj17"
      },
      "source": [
        "**How many samples and features are in the dataset?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7q3D-1vissTD"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "n_train_binary_samples = ...\n",
        "print(\"The number of samples for training: \", n_train_binary_samples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "n_test_binary_samples = ...\n",
        "print(\"The number of samples for test: \", n_test_binary_samples)"
      ],
      "metadata": {
        "id": "0wYtfiwKq8bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m19LbXGUh5Vg"
      },
      "source": [
        "We will also inspect the number of samples in each category of the target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QGClXoWjh4qc"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzoKKZo1fd9P"
      },
      "source": [
        "## 5.2 Binary classification performance\n",
        "\n",
        "In addition to accuracy, we will evaluate binary classification performance using two additional metrics: the confusion matrix and the ROC (Receiver Operating Characteristic) curve (along with the AUC score).\n",
        "\n",
        "The **confusion matrix** provides valuable insights in binary classification by displaying the counts of true positives, true negatives, false positives, and false negatives. These values allow us to compute specific probabilities, such as:\n",
        "*   **False alarm rate**: The likelihood of incorrectly predicting the positive class.\n",
        "*   **Miss rate**: The probability of failing to detect a true positive.\n",
        "*   **Detection rate**: The probability of correctly identifying a positive instance.\n",
        "\n",
        "Although commonly used in binary classification, the confusion matrix can also be applied to multiclass problems, where it expands into a grid with each cell representing the count of predictions for each actual class versus each predicted class. This provides a detailed view of misclassifications across multiple classes, helping to pinpoint areas where the model may struggle with specific categories.\n",
        "\n",
        "\n",
        "The **ROC curve** and **AUC score**, on the other hand, provide valuable insight into the model's ability to distinguish between classes by illustrating the trade-off between the true positive rate and the false positive rate across various thresholds.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbiw_Ds9jkSW"
      },
      "source": [
        "### 5.2.1 Confusion matrix\n",
        "\n",
        " For **binary classification**, the confusion matrix is a $2\\times2$ grid that displays the counts of:\n",
        "\n",
        "*   **True Positives** (TP): Correctly predicted positive samples.\n",
        "*   **True Negatives** (TN): Correctly predicted negative samples.\n",
        "*   **False Positives** (FP): Incorrectly predicted positive samples (commonly referred to as Type I errors).\n",
        "*   **False Negative**s (FN): Incorrectly predicted negative samples (commonly referred to as Type II errors).\n",
        "\n",
        "Below is a visual representation of a confusion matrix for binary classification:\n",
        "\n",
        "\n",
        "\\begin{array}{c|cc}\n",
        "           & \\text{Predicted Positive} & \\text{Predicted Negative} \\\\\n",
        "    \\hline\n",
        "    \\text{Actual Positive} & \\text{TP} & \\text{FN}\\\\\n",
        "    \\text{Actual Negative} & \\text{FP} & \\text{TN} \\\\\n",
        "\\end{array}\n",
        "\n",
        "\n",
        "\n",
        "This layout helps us derive specific metrics, such as the probability of false alarm, miss, and detection, as discussed in the previous section.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Hc-ihnmgWq"
      },
      "source": [
        "### 5.2.2 ROC Curve and AUC Score\n",
        "\n",
        "The **ROC Curve** is a graphical representation of a classification model’s ability to distinguish between classes at various threshold levels. It plots the **True Positive Rate** (TPR)—also known as *sensitivity* or *recall*—on the y-axis against the **False Positive Rate** (FPR) on the x-axis, where:\n",
        "\n",
        "*   **True Positive Rate** (TPR):  The proportion of actual positives correctly classified by the model:\n",
        "\n",
        "  $$\\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$\n",
        "  \n",
        "*   **False Positive Rate** (FPR): The proportion of actual negatives incorrectly classified as positives:\n",
        "$$\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$$\n",
        "\n",
        "An ideal ROC curve will pass through the top left corner of the plot (TPR $= 1$, FPR $= 0$), representing a perfect classifier with high sensitivity and no false positives.\n",
        "\n",
        "\n",
        "**AUC (Area Under the Curve)** quantifies the overall ability of the model to distinguish between positive and negative classes, regardless of the threshold. The AUC score ranges from $0$ to $1$, where:\n",
        "*  **AUC = 1**: It represents a perfect classifier.\n",
        "*  **AUC = 0.5**: It represents a model with no discriminative power, equivalent to random guessing.\n",
        "*  **AUC < 0.5**: It indicates that the model is performing worse than random guessing.\n",
        "\n",
        "A higher AUC score reflects better model performance, as it signifies stronger discrimination between the positive and negative classes across all possible thresholds.\n",
        "\n",
        "The ROC Curve and AUC score together provide a holistic evaluation of model performance, especially in scenarios with imbalanced datasets, where metrics like accuracy can be misleading. AUC is particularly valuable as it remains unaffected by class distribution, highlighting the model's robustness in handling varying thresholds.\n",
        "\n",
        "\n",
        "> **Implementation in Python:**\n",
        "\n",
        "> To compute and visualize the ROC curve along with the AUC score using `scikit-learn` and `matplotlib`, you can follow these steps:\n",
        "\n",
        "  1.   Compute the FPR and TPR: Use [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve) with the true labels and predicted probabilities.\n",
        "  2.   Calculate the AUC: Use [auc](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc) with the FPR and TPR values.\n",
        "  3. Visualize the ROC Curve: Use matplotlib to plot the ROC curve.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dgZ3tc4VEYw"
      },
      "source": [
        "## 5.3 Implementation and evaluation of logistic regressor clasifier's performance\n",
        "\n",
        "**Logistic Regression** (LR) is a classification method commonly used for **binary classification problems**. It models the probability of a sample belonging to a particular class by applying a logistic function to a linear combination of the input features. This produces output values between $0$ and $1$, which can be interpreted as probabilities, creating linear decision boundaries. LR is effective for binary classification and can also be extended to multiclass problems through the one-vs-rest or multinomial approach. This approach is out of the scope of this assignment; for this reason, this classifier has been implemented to solve a binary classification problem.\n",
        "\n",
        "To implement a logistic regression classifier in Python, we will use the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) class from `scikit-learn`, which performs regularized logistic regression. This involves adding a penalty term (controlled by the `penalty` hyperparameter) to the loss function to prevent overfitting by discouraging large coefficient values. The available regularization options include:\n",
        "*   **$\\ell_1$ regularization**: It adds an $\\ell_1$ penalty, which is the absolute value of the coefficients' magnitudes. This method is similar to that used in Lasso regression and encourages sparsity in the model.\n",
        "*   **$\\ell_2$ regularization**: It adds an $\\ell_2$ penalty, which is the square of the coefficients' magnitudes. This method is the default choice and is similar to Ridge or Kernel Ridge regression, resulting in a more stable solution without necessarily forcing coefficients to zero.\n",
        "\n",
        "We can also choose to disable regularization by setting the parameter `penalty` to `None`.\n",
        "\n",
        "The strength of regularization is controlled by the hyperparameter `C`, which is the inverse of regularization strength and must be a positive float. Smaller values of `C` imply stronger regularization, similar to the behavior of the `alpha` hyperparameter in Lasso, Ridge, and KernelRidge models in `scikit-learn`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYnX5FPfb5Fz"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "*   Find the optimal values for `C` and `penalty`. To do so, implement a grid search using `GridSearchCV` with standardized features to optimize the classifier's performance. The values to be explored are listed below:\n",
        "\n",
        "\n",
        "\n",
        "*   Once the optimal hyperparameters have been found, use the `best_estimator_` attribute of `GridSearchCV` to calculate the accuracy rate on the test set and print the result. Please round the value to two decimal places.\n",
        "\n",
        "**Your task here is as follows:**\n",
        "\n",
        "1.   **Hyperparameter tuning**\n",
        "\n",
        "  Use the `GridSearchCV` class to find the optimal values for `C` (the value of $k$) and `penalty`. Perform the grid search with **standardized features** to optimize the classifier's performance. The parameter values to explore are:\n",
        "  * `C` $ \\in \\{0.01,0.05, 0.1, 0.5, 1, 5, 1\\}$\n",
        "  * `penalty` $\\in$ {`L1`, `L2`}.\n",
        "2.   **Evaluate the best model**\n",
        "  Once the optimal hyperparameters are identified, calculate the accuracy rate (as a percentage) on the test set using the `best_estimator_` attribute of `GridSearchCV`. Print the result, rounding it to two decimal places.\n",
        "\n",
        "Please note that if the model was **trained** using the **standardized dataset**, it must also be **evaluated** on the **standardized test set** to ensure consistency in the feature scaling.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9GcZSS7JHH6e"
      },
      "outputs": [],
      "source": [
        "#Fine-tuning hyperparameters\n",
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hMVLGyIQxoo-"
      },
      "outputs": [],
      "source": [
        "#Check the best model with the test set\n",
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0tB4YW9sDD8"
      },
      "source": [
        "---\n",
        "**Question:** What are the most appropriate values of the hyperparameters `C` and `penalty` that you have obtained?\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sim7dsnzkxQ"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "* Calculate the **confusion matrix** for the **test set** using the **best model** obtained from the **grid search**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VcXxf6iZyHlY"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-I7RVC9NRi2"
      },
      "source": [
        "\n",
        "---\n",
        "**Question:** Using the confusion matrix, indicate the number of True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX-p3tfv0Cvx"
      },
      "source": [
        "---\n",
        "**Question:** How can you compute the accuracy rate, the probability of false alarm, and the probability of miss from the confusion matrix?\"\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC4URgKGe-3l"
      },
      "source": [
        "**Your task here is as follows:**\n",
        "\n",
        "*   Plot the ROC curve for the LR classifier using the **test set**.\n",
        "*   Calculate the AUC and display the result.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  $\\underline{\\text{Hint}}$: Remember that the `y_score` parameter in [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve) represents the probability estimates for the positive class. In binary classification, the `predict_proba` method provides probability estimates for each class, specifically the likelihood that a sample belongs to the negative or positive class. The second column corresponds to the probability that a sample belongs to the positive class. By utilizing only these probabilities, the ROC curve assesses classifier performance over a range of thresholds. If the probability exceeds a given threshold (e.g., $0.5$), the sample is classified as positive; otherwise, it is classified as negative.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uhSxUhqTfB0p"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSZNfmp1iXb4"
      },
      "source": [
        "\n",
        "---\n",
        "**Question:** What is the value of AUC metric for the test set?\n",
        "\n",
        "\n",
        "<font color = 'green'> YOUR ANSWER HERE\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}