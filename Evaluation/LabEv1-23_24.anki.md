# 2. MTDE::2.2. Classification::Lab Evaluation 23/24

<style>
hr { border-style: dashed; }
</style>

## <!-- MARK: LabEv2 23-24 Q1 -->
Which technique has been employed in the assignment to determine the optimal
value of $k$ in the $k$-Nearest Neighbors ($k$-NN) algorithm?

* [ ] a) Grid search.
* [ ] b) Using a validation set.
* [ ] c) Linear Discriminant Analysis (LDA).
* [ ] d) None of the above answers is correct.

***

* [x] a) Grid search.

## <!-- Mark: LabEv2 23-24 Q2 -->
What does the attribute `best_params_` included in the class `GridSearchCV`
return?

* [ ] a) The estimator which gave highest score on the left out data.
* [ ] b) The mean cross-validated score of the `best_estimator_`.
* [ ] c) The index which corresponds to the best candidate parameter setting.
* [ ] d) The parameter setting that gave the best results on the hold out data.

***

* [x] d) The parameter setting that gave the best results on the hold out data.

## <!-- Mark: LabEv2 23-24 Q3 -->
Point out which statement, according to the performance of a binary
classification algorithm, is correct.

* [ ] a) If the value of AUC is 0, there is a classification threshold for which
  the accuracy rate is 1.
* [ ] b) If the value of AUC is 1, there is a classification threshold for which
  the error rate is 1.
* [ ] c) If the value of AUC is 1, there is a classification threshold for which
  the error rate is 0.
* [ ] d) If the value of AUC is 0, there is a classification threshold for which
  the error rate is 0.

***

* [x] c) If the value of AUC is 1, there is a classification threshold for which

## <!-- Mark: LabEv2 23-24 Q4 -->
Have a look at the following code snippets:

```python
from sklearn.metrics import roc_curve
FPR, TPR, Thresholds = roc_curve(y_test, scores)
```

What do scores represent?

* [ ] a) The probability estimates of the negative class.
* [ ] b) The predicted class labels for samples in the test subset.
* [ ] c) The probability estimates of the positive class.
* [ ] d) The mean accuracy on the given test data and labels.

***

* [x] c) The probability estimates of the positive class.

## <!-- Mark: LabEv2 23-24 Q5 -->
Point out which statement, according to the confusion matrix, is false.

* [ ] a) The sum of the diagonal elements indicates how many samples have been
  correctly classified.
* [ ] b) It can be approximately computed both the probability of missing and
  the probability of false alarm from the elements of the matrix.
* [ ] c) It can be approximately computed both the accuracy and error rates from
  the elements of the matrix.
* [ ] d) It is a symmetric matrix.

***

* [x] d) It is a symmetric matrix.

## <!-- Mark: LabEv2 23-24 Q6 -->
Point out which statement, according to the ROC curve calculated in the
assignment, is false.

* [ ] a) The ROC curve is increasing.
* [ ] b) It passes through the point (0, 0).
* [ ] c) It passes through the point (1, 1).
* [ ] d) It passes through the point (0, 1).

***

* [x] d) It passes through the point (0, 1).

## <!-- Mark: LabEv2 23-24 Q7 -->
Point out which statement, according to the experiments carried out in the
assignment, with the class `RandomForestClassifier` in `sklearn`, is correct.

* [ ] a) It is necessary to standardize the data aiming at achieving good
  performance.
* [ ] b) The hyperparameters which have been fine-tuning are `penalty` and `C`.
* [ ] c) It is composed of a set of classifiers based on the $k$-NN algorithm
  (class `KNeighborsClassifier`).
* [ ] d) None of the above answers is correct.

***

* [x] d) None of the above answers is correct.

## <!-- Mark: LabEv2 23-24 Q8 -->
Have a look at the following code snippets:

```python
from sklearn.linear_model import LogisticRegression
LogisticRegression().fit(X_train_s,y_train)
```

What does the method `fit` in the class `LogisticRegression` perform?

* [ ] a) It returns the mean accuracy on the given training data and labels.
* [ ] b) It predicts class labels for samples in `X_train_s`.
* [ ] c) It obtains the value of `C` (inverse of regularization strength).
* [ ] d) It computes the coefficients of the model according to the given
  training data.

***

* [x] d) It computes the coefficients of the model according to the given
  training data.

## <!-- Mark: LabEv2 23-24 Q9 -->
Which of the following code snippets demonstrates the way used in the assignment
to standardize the feature values for the training subset?

* [ ] a)

    ```python
    from sklearn.preprocessing import StandardScaler
    X_train_scaled = StandardScaler().fit_transform(X_train)
    ```

* [ ] b)

    ```python
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    X_train_scaled = scaler.fit(X_train)
    ```

* [ ] c)

    ```python
    from sklearn.preprocessing import Normalizer
    scaler = Normalizer()
    X_train_scaled = scaler.fit_transform(X_train)
    ```

* [ ] d) None of the above answers is correct.

***

* [x] a)

    ```python
    from sklearn.preprocessing import StandardScaler
    X_train_scaled = StandardScaler().fit_transform(X_train)
    ```

## <!-- Mark: LabEv2 23-24 Q10 -->
Have a look at the following code snippets:

```python
v_ntrees = [10, 20, 50, 100, 125, 150]
depth = [5,10,15,20]
parameters_rf = {’n_estimators’: v_ntrees, ’max_depth’: depth}
rf = RandomForestClassifier()
grid_rf = GridSearchCV(rf, parameters_rf,cv=5)
grid_rf.fit(X_train, y_train)
```

How many classification models are created and fitted when the method fit is
runned?

* [ ] a) **10** models aiming at obtaining the optimal values of the
  hyperparameters + 1 (final) model using the aforementioned values.
* [ ] b) **24** models aiming at obtaining the optimal values of the
  hyperparameters + 1 (final) model using the aforementioned values.
* [ ] c) **120** models aiming at obtaining the optimal values of the
  hyperparameters + 1 (final) model using the aforementioned values.
* [ ] d) **50** models aiming at obtaining the optimal values of the
  hyperparameters + 1 (final) model using the aforementioned values.

***

* [x] c) **120** models aiming at obtaining the optimal values of the
  hyperparameters + 1 (final) model using the aforementioned values.
